Thesis Project on Usefulness of LLMs in Test Case Generation

Description

This repository hosts datasets used in my thesis project, which investigates the utility of Large Language Models (LLMs), specifically GPT-3.5 and LLaMA2, in generating test cases. The focus is on comparing these two models based on several evaluation criteria: effectiveness, efficiency, and Innovativeness. The datasets include generated test cases that serve as a basis for this comparison. There are also Python codes for generating and analyzing these datasets for the mentioned criteria.

Datasets:

GPT_generated_test_cases.csv:

Content: Contains test cases generated by GPT-3.5, designed to assess the model's ability to produce relevant and comprehensive scenarios that align with specified requirements.

Source: Generated through the provided Python code simulating using GPT-3.5.

Purpose: To evaluate the effectiveness of GPT-3.5 in test case generation, focusing on effectiveness, efficiency, and Innovativeness.

LLaMA2_generated_test_cases.csv:
Content: Includes test cases generated by LLaMA2, focusing on the model's capacity to deliver specific, correct, innovative, and creative test scenarios.

Source: Generated via the provided Python code simulating employing LLaMA2.

Purpose: To compare LLaMA2's performance against GPT-3.5 in terms of effectiveness, efficiency, and innovativeness in test case production.

These datasets are intended for academic research and educational purposes within the scope of evaluating LLM capabilities in software testing. If using these datasets in your study or projects, please cite this repository.
