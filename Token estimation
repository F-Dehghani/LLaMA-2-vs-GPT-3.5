# Function to estimate the number of tokens in a text
def estimate_tokens(text):
    return len(text.split())

# Estimate tokens for a few entries to get an average per test case
gpt_input_tokens = gpt_data['Scenarios Input'].apply(estimate_tokens)
gpt_output_tokens = gpt_data['Testcases'].apply(estimate_tokens)
llama_input_tokens = llama_data['Scenarios Input'].apply(estimate_tokens)
llama_output_tokens = llama_data['Testcases'].apply(estimate_tokens)

# average tokens for inputs and outputs
average_tokens__gpt = (gpt_input_tokens + gpt_output_tokens).mean()
average_tokens_llama = (llama_input_tokens + llama_output_tokens).mean()

# Display the average token count per test case
average_tokens_per_case_gpt, average_tokens_per_case_llama
